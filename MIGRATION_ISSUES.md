# DeepSeek-OCR API æœåŠ¡è¿ç§»é—®é¢˜æ€»ç»“

æœ¬æ–‡æ¡£è®°å½•äº†ä»åŸå§‹ DeepSeek-OCR é¡¹ç›®è¿ç§»åˆ°ç‹¬ç«‹ API æœåŠ¡ä»“åº“æ—¶é‡åˆ°çš„é—®é¢˜åŠå…¶è§£å†³æ–¹æ¡ˆã€‚

---

## ç›®å½•

- [é—®é¢˜æ¦‚è§ˆ](#é—®é¢˜æ¦‚è§ˆ)
- [æ ¸å¿ƒé—®é¢˜ï¼šconfig.py æ–‡ä»¶é”™è¯¯](#1-æ ¸å¿ƒé—®é¢˜configpy-æ–‡ä»¶é”™è¯¯)
- [TOKENIZER å¯¹è±¡å¼•ç”¨é”™è¯¯](#2tokenizer-å¯¹è±¡å¼•ç”¨é”™è¯¯)
- [Conda ç¯å¢ƒæœªæ¿€æ´»](#3conda-ç¯å¢ƒæœªæ¿€æ´»)
- [GPU å†…å­˜å ç”¨é—®é¢˜](#4gpu-å†…å­˜å ç”¨é—®é¢˜)
- [æ ¹æœ¬åŸå› åˆ†æ](#æ ¹æœ¬åŸå› åˆ†æ)
- [ç»éªŒæ•™è®­](#ç»éªŒæ•™è®­)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## é—®é¢˜æ¦‚è§ˆ

åœ¨è¿ç§»å’Œå¯åŠ¨ DeepSeek-OCR API æœåŠ¡çš„è¿‡ç¨‹ä¸­ï¼Œä¸»è¦é‡åˆ°äº†ä»¥ä¸‹é—®é¢˜ï¼š

| # | é—®é¢˜ | é”™è¯¯ä¿¡æ¯ | ä¸¥é‡ç¨‹åº¦ |
|---|------|---------|---------|
| 1 | `config.py` æ–‡ä»¶å†…å®¹é”™è¯¯ | å¯¼å…¥å¤±è´¥ | ğŸ”´ ä¸¥é‡ |
| 2 | TOKENIZER ç±»å‹é”™è¯¯ | `AttributeError: 'str' object has no attribute 'padding_side'` | ğŸ”´ ä¸¥é‡ |
| 3 | Conda ç¯å¢ƒæœªæ¿€æ´» | `ModuleNotFoundError: No module named 'vllm'` | ğŸŸ¡ ä¸­ç­‰ |
| 4 | GPU å†…å­˜è¢«å ç”¨ | `CUDA out of memory` | ğŸŸ¡ ä¸­ç­‰ |

---

## 1. æ ¸å¿ƒé—®é¢˜ï¼šconfig.py æ–‡ä»¶é”™è¯¯

### é—®é¢˜æè¿°

åœ¨åˆ›å»ºé¡¹ç›®è¾…åŠ©æ–‡ä»¶ï¼ˆ.gitignoreã€LICENSE ç­‰ï¼‰æ—¶ï¼Œ**è¯¯å†™**äº†æ ¹ç›®å½•çš„ `config.py` æ–‡ä»¶ï¼Œå°†å…¶æ›¿æ¢æˆäº† API æœåŠ¡é…ç½®å†…å®¹ï¼Œå¯¼è‡´æ¨¡å‹é…ç½®å‚æ•°ä¸¢å¤±ã€‚

### é”™è¯¯å†…å®¹

**æˆ‘é”™è¯¯åˆ›å»ºçš„å†…å®¹ï¼š**
```python
"""
APIæœåŠ¡é…ç½®ç®¡ç†æ¨¡å—
ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼Œæä¾›é»˜è®¤å€¼å’ŒéªŒè¯
"""
import os
from typing import List
from pathlib import Path

class Config:
    """APIæœåŠ¡é…ç½®ç±»"""
    API_HOST: str = os.getenv("API_HOST", "0.0.0.0")
    API_PORT: int = int(os.getenv("API_PORT", "8080"))
    # ... æ›´å¤š API é…ç½®
```

### æ­£ç¡®å†…å®¹

**åº”è¯¥åŒ…å«çš„æ¨¡å‹é…ç½®ï¼š**
```python
# DeepSeek-OCR æ¨¡å‹é…ç½®
# å®šä¹‰å›¾åƒå¤„ç†å’Œæ¨¡å‹æ¨ç†æ‰€éœ€çš„å‚æ•°

# TODO: change modes
# Tiny: base_size = 512, image_size = 512, crop_mode = False
# Small: base_size = 640, image_size = 640, crop_mode = False
# Base: base_size = 1024, image_size = 1024, crop_mode = False
# Large: base_size = 1280, image_size = 1280, crop_mode = False
# Gundam: base_size = 1024, image_size = 640, crop_mode = True

BASE_SIZE = 1024
IMAGE_SIZE = 640
CROP_MODE = True
MIN_CROPS = 2
MAX_CROPS = 6  # max:9; If your GPU memory is small, it is recommended to set it to 6.
MAX_CONCURRENCY = 100  # If you have limited GPU memory, lower the concurrency count.
NUM_WORKERS = 64  # image pre-process (resize/padding) workers
PRINT_NUM_VIS_TOKENS = False
SKIP_REPEAT = True
MODEL_PATH = '/hy-tmp/deepseek-ocr-model'  # change to your model path

# TODO: change INPUT_PATH
# .pdf: run_dpsk_ocr_pdf.py;
# .jpg, .png, .jpeg: run_dpsk_ocr_image.py;
# Omnidocbench images path: run_dpsk_ocr_eval_batch.py

INPUT_PATH = ''
OUTPUT_PATH = ''

PROMPT = '<image>\n<|grounding|>Convert the document to markdown.'
# PROMPT = '<image>\nFree OCR.'
# TODO commonly used prompts
# document: <image>\n<|grounding|>Convert the document to markdown.
# other image: <image>\n<|grounding|>OCR this image.
# without layouts: <image>\nFree OCR.
# figures in document: <image>\nParse the figure.
# general: <image>\nDescribe this image in detail.
# rec: <image>\nLocate <|ref|>xxxx<|/ref|> in the image.
# 'å…ˆå¤©ä¸‹ä¹‹å¿§è€Œå¿§'
# .......


from transformers import AutoTokenizer

TOKENIZER = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
```

### å½±å“èŒƒå›´

- âŒ `process/image_process.py` æ— æ³•å¯¼å…¥é…ç½®å‚æ•°
- âŒ `deepseek_ocr.py` æ— æ³•å¯¼å…¥ `IMAGE_SIZE`, `BASE_SIZE` ç­‰
- âŒ æ•´ä¸ªé¡¹ç›®æ— æ³•æ­£å¸¸åˆå§‹åŒ–

---

## 2. TOKENIZER å¯¹è±¡å¼•ç”¨é”™è¯¯

### é—®é¢˜æè¿°

å³ä½¿ config.py å­˜åœ¨ï¼Œå¦‚æœ TOKENIZER è¢«å®šä¹‰ä¸ºå­—ç¬¦ä¸²è€Œéå®é™…å¯¹è±¡ï¼Œä¼šå¯¼è‡´å±æ€§è®¿é—®é”™è¯¯ã€‚

### é”™è¯¯ä¿¡æ¯

```
Traceback (most recent call last):
  File "/root/deepseek-ocr-api-service/process/image_process.py", line 149, in __init__
    self.tokenizer.padding_side = 'left'
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'padding_side'
```

### é”™è¯¯åŸå› 

**é”™è¯¯çš„å®šä¹‰æ–¹å¼ï¼š**
```python
# âŒ é”™è¯¯ï¼šTOKENIZER æ˜¯å­—ç¬¦ä¸²
TOKENIZER = "deepseek-ai/DeepSeek-OCR"
```

**æ­£ç¡®çš„å®šä¹‰æ–¹å¼ï¼š**
```python
# âœ… æ­£ç¡®ï¼šTOKENIZER æ˜¯å®é™…å¯¹è±¡
from transformers import AutoTokenizer

TOKENIZER = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
```

### ä»£ç ä¾èµ–å…³ç³»

`process/image_process.py` ä¸­çš„ `DeepseekOCRProcessor` ç±»ï¼š

```python
class DeepseekOCRProcessor(ProcessorMixin):
    def __init__(
        self,
        tokenizer: LlamaTokenizerFast = TOKENIZER,  # æœŸæœ›å¯¹è±¡ï¼Œä¸æ˜¯å­—ç¬¦ä¸²
        # ... å…¶ä»–å‚æ•°
    ):
        self.tokenizer = tokenizer
        self.tokenizer.padding_side = 'left'  # â† è¿™é‡Œå¤±è´¥
```

---

## 3. Conda ç¯å¢ƒæœªæ¿€æ´»

### é—®é¢˜æè¿°

ç›´æ¥ä½¿ç”¨ç³»ç»Ÿ Python è¿è¡ŒæœåŠ¡ï¼Œå¯¼è‡´æ‰¾ä¸åˆ° `vllm` æ¨¡å—ã€‚

### é”™è¯¯ä¿¡æ¯

```
Traceback (most recent call last):
  File "/root/deepseek-ocr-api-service/api_service/run_server.py", line 16, in <module>
    uvicorn.run(
  ...
  File "/root/deepseek-ocr-api-service/api_service/model_manager.py", line 15, in <module>
    from vllm import AsyncLLMEngine, SamplingParams
ModuleNotFoundError: No module named 'vllm'
```

### åŸå› åˆ†æ

- `vllm`ã€`flash-attn` ç­‰ä¾èµ–å®‰è£…åœ¨ conda ç¯å¢ƒ `deepseek-ocr` ä¸­
- ç›´æ¥ä½¿ç”¨ `python run_server.py` ä¼šä½¿ç”¨ç³»ç»Ÿé»˜è®¤ Python
- ç³»ç»Ÿç¯å¢ƒä¸­æ²¡æœ‰å®‰è£…è¿™äº›æ·±åº¦å­¦ä¹ ä¾èµ–

### è§£å†³æ–¹æ¡ˆ

**å¯åŠ¨æœåŠ¡æ—¶å¿…é¡»æ¿€æ´»ç¯å¢ƒï¼š**
```bash
source /usr/local/miniconda3/etc/profile.d/conda.sh
conda activate deepseek-ocr
cd /root/deepseek-ocr-api-service/api_service
python run_server.py
```

**æˆ–è€…åœ¨å¯åŠ¨è„šæœ¬ä¸­æ·»åŠ ï¼š**
```bash
#!/bin/bash
# start.sh

# æ¿€æ´» conda ç¯å¢ƒ
source /usr/local/miniconda3/etc/profile.d/conda.sh
conda activate deepseek-ocr

# å¯åŠ¨æœåŠ¡
python run_server.py
```

---

## 4. GPU å†…å­˜å ç”¨é—®é¢˜

### é—®é¢˜æè¿°

é¦–æ¬¡å¯åŠ¨æ—¶é‡åˆ° GPU å†…å­˜ä¸è¶³é”™è¯¯ï¼Œä½†å®é™…ä¸Š GPU æœ‰ 24GBï¼Œæ¨¡å‹åªéœ€è¦çº¦ 17GBã€‚

### é”™è¯¯ä¿¡æ¯

```
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 906.00 MiB.
GPU 0 has a total capacity of 23.69 GiB of which 775.00 MiB is free.
Process 2789321 has 10.13 GiB memory in use.
Process 2813720 has 12.80 GiB memory in use.
```

### åŸå› åˆ†æ

**ä¸æ˜¯çœŸæ­£çš„å†…å­˜ä¸è¶³ï¼Œè€Œæ˜¯æœ‰å…¶ä»–è¿›ç¨‹å ç”¨ï¼š**
- Process 2789321: 10.13 GiB
- Process 2813720: 12.80 GiB
- æ€»è®¡çº¦ 23GBï¼Œå‡ ä¹å æ»¡ 24GB

**å¯èƒ½æ˜¯ï¼š**
1. ä¹‹å‰å¯åŠ¨å¤±è´¥çš„æ¨¡å‹å®ä¾‹æ²¡æœ‰æ­£ç¡®æ¸…ç†
2. å…¶ä»–æœåŠ¡æ­£åœ¨ä½¿ç”¨ GPU
3. Jupyter Notebook æˆ–å…¶ä»–äº¤äº’å¼ä¼šè¯å ç”¨

### è§£å†³æ–¹æ¡ˆ

**æ£€æŸ¥ GPU ä½¿ç”¨æƒ…å†µï¼š**
```bash
nvidia-smi
```

**ç­‰å¾…è¿›ç¨‹é‡Šæ”¾å†…å­˜æˆ–æ‰‹åŠ¨ç»ˆæ­¢ï¼š**
```bash
# æŸ¥çœ‹å ç”¨ GPU çš„ Python è¿›ç¨‹
ps aux | grep python

# å¦‚æœç¡®è®¤å¯ä»¥ç»ˆæ­¢ï¼Œä½¿ç”¨ kill å‘½ä»¤
kill <PID>
```

**éªŒè¯ GPU å·²é‡Šæ”¾ï¼š**
```bash
nvidia-smi
# åº”è¯¥çœ‹åˆ° "No running processes found" æˆ–å¾ˆå°çš„å†…å­˜å ç”¨
```

---

## æ ¹æœ¬åŸå› åˆ†æ

### é¡¹ç›®ç»“æ„ç†è§£ä¸è¶³

**åŸå§‹é¡¹ç›®ç»“æ„ï¼š**
```
/hy-tmp/DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm/
â”œâ”€â”€ config.py              # â† æ¨¡å‹é…ç½®ï¼ˆè¢«é—æ¼ï¼‰
â”œâ”€â”€ deepseek_ocr.py
â”œâ”€â”€ process/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ image_process.py   # ä¾èµ– config.py
â”‚   â””â”€â”€ ngram_norepeat.py
â”œâ”€â”€ deepencoder/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ build_linear.py
â”‚   â”œâ”€â”€ clip_sdpa.py
â”‚   â””â”€â”€ sam_vary_sdpa.py
â””â”€â”€ api_service/
    â”œâ”€â”€ config.py          # â† API é…ç½®ï¼ˆä¸åŒæ–‡ä»¶ï¼‰
    â”œâ”€â”€ main.py
    â”œâ”€â”€ model_manager.py
    â””â”€â”€ ...
```

### ä¸¤ä¸ª config.py çš„åŒºåˆ«

| ç‰¹æ€§ | æ ¹ç›®å½• `config.py` | `api_service/config.py` |
|------|-------------------|----------------------|
| **ç”¨é€”** | æ¨¡å‹é…ç½® | API æœåŠ¡é…ç½® |
| **å†…å®¹** | IMAGE_SIZE, TOKENIZER, PROMPT ç­‰ | API_PORT, API_KEYS ç­‰ |
| **å¯¼å…¥è€…** | process/, deepseek_ocr.py | api_service/ æ¨¡å— |
| **åˆå§‹åŒ–æ—¶æœº** | æ¨¡å—åŠ è½½æ—¶ | æœåŠ¡å¯åŠ¨æ—¶ |
| **ç±»å‹** | å…¨å±€å˜é‡ | Config ç±» |

### è¿ç§»æ—¶çš„ç–æ¼

**é”™è¯¯çš„æ“ä½œæµç¨‹ï¼š**
1. âœ… å¤åˆ¶äº† `api_service/` ç›®å½•
2. âœ… å¤åˆ¶äº† `process/` ç›®å½•
3. âœ… å¤åˆ¶äº† `deepencoder/` ç›®å½•
4. âœ… å¤åˆ¶äº† `deepseek_ocr.py`
5. âŒ **å¿˜è®°**å¤åˆ¶æ ¹ç›®å½•çš„ `config.py`
6. âŒ åæ¥åˆ›å»º `.env.template` æ—¶**è¯¯å†™**äº† `config.py`

**åº”è¯¥çš„æ“ä½œæµç¨‹ï¼š**
```bash
# å®Œæ•´å¤åˆ¶æ‰€æœ‰å¿…è¦æ–‡ä»¶
cp /hy-tmp/DeepSeek-OCR/.../config.py /root/.../config.py
cp /hy-tmp/DeepSeek-OCR/.../deepseek_ocr.py /root/.../
cp -r /hy-tmp/DeepSeek-OCR/.../process /root/.../
cp -r /hy-tmp/DeepSeek-OCR/.../api_service /root/.../
```

---

## ç»éªŒæ•™è®­

### 1. é…ç½®æ–‡ä»¶è¦æ˜ç¡®å‘½å

é¿å…ä½¿ç”¨é€šç”¨åç§°ï¼Œä½¿ç”¨æ›´å…·æè¿°æ€§çš„æ–‡ä»¶åï¼š

```
config.py              # â†’ model_config.py
api_config.py          # â†’ api_service_config.py
```

### 2. è¿ç§»æ—¶æ£€æŸ¥ä¾èµ–å…³ç³»

**ä½¿ç”¨å·¥å…·æ£€æŸ¥å¯¼å…¥ä¾èµ–ï¼š**
```bash
# æŸ¥æ‰¾æ‰€æœ‰å¯¼å…¥ config çš„æ–‡ä»¶
grep -r "from config import" --include="*.py"

# æŸ¥æ‰¾æ‰€æœ‰å¯¼å…¥ TOKENIZER çš„æ–‡ä»¶
grep -r "TOKENIZER" --include="*.py"
```

### 3. å…³é”®æ–‡ä»¶è¦å¤‡ä»½

```bash
# è¿ç§»å‰å¤‡ä»½
tar -czf deepseek-ocr-backup.tar.gz /hy-tmp/DeepSeek-OCR/

# å¯¹æ¯”æ–‡ä»¶å·®å¼‚
diff /hy-tmp/.../config.py /root/.../config.py
```

### 4. åˆ†æ­¥éªŒè¯å¯åŠ¨

**ä¸è¦ä¸€æ¬¡æ€§å¯åŠ¨æ•´ä¸ªæœåŠ¡ï¼Œè€Œæ˜¯é€æ­¥éªŒè¯ï¼š**

```bash
# ç¬¬ 1 æ­¥ï¼šéªŒè¯ç¯å¢ƒ
python -c "import vllm; print('vLLM OK')"
python -c "import torch; print('PyTorch OK', torch.__version__)"

# ç¬¬ 2 æ­¥ï¼šéªŒè¯é…ç½®
python -c "from config import TOKENIZER; print(type(TOKENIZER))"
# è¾“å‡ºåº”è¯¥æ˜¯: <class 'transformers.models.llama.tokenization_llama.LlamaTokenizerFast'>

# ç¬¬ 3 æ­¥ï¼šéªŒè¯æ¨¡å‹å¯¼å…¥
python -c "from deepseek_ocr import DeepseekOCRForCausalLM; print('Model OK')"

# ç¬¬ 4 æ­¥ï¼šéªŒè¯å¤„ç†å™¨
python -c "from process.image_process import DeepseekOCRProcessor; print('Processor OK')"

# ç¬¬ 5 æ­¥ï¼šå¯åŠ¨æœåŠ¡
python run_server.py
```

### 5. ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶é¿å…ä¸¢å¤±

```bash
# æ·»åŠ æ‰€æœ‰æ–‡ä»¶åˆ° Git
git add config.py process/ deepencoder/ deepseek_ocr.py

# æäº¤å‰æ£€æŸ¥çŠ¶æ€
git status

# æŸ¥çœ‹å³å°†æäº¤çš„å†…å®¹
git diff --cached

# ç¡®è®¤æ— è¯¯åæäº¤
git commit -m "feat: add model files"
```

---

## æœ€ä½³å®è·µ

### è¿ç§»æ£€æŸ¥æ¸…å•

- [ ] **ç¯å¢ƒå‡†å¤‡**
  - [ ] åˆ›å»º/æ¿€æ´»æ­£ç¡®çš„ conda ç¯å¢ƒ
  - [ ] éªŒè¯ä¾èµ–åŒ…ç‰ˆæœ¬
  - [ ] æ£€æŸ¥ CUDA ç‰ˆæœ¬å…¼å®¹æ€§

- [ ] **æ–‡ä»¶å¤åˆ¶**
  - [ ] åˆ—å‡ºæ‰€æœ‰éœ€è¦å¤åˆ¶çš„æ–‡ä»¶
  - [ ] æ£€æŸ¥å¯¼å…¥ä¾èµ–å…³ç³»
  - [ ] å¤åˆ¶é…ç½®æ–‡ä»¶ï¼ˆæ³¨æ„åŒåæ–‡ä»¶ï¼‰
  - [ ] å¤åˆ¶æºä»£ç æ–‡ä»¶
  - [ ] å¤åˆ¶èµ„æºæ–‡ä»¶ï¼ˆæ¨¡å‹æƒé‡ç­‰ï¼‰

- [ ] **é…ç½®è°ƒæ•´**
  - [ ] æ›´æ–°è·¯å¾„é…ç½®
  - [ ] æ›´æ–°ç«¯å£é…ç½®
  - [ ] æ›´æ–° API Keys
  - [ ] æ£€æŸ¥ç¯å¢ƒå˜é‡

- [ ] **éªŒè¯æµ‹è¯•**
  - [ ] æµ‹è¯•å¯¼å…¥
  - [ ] æµ‹è¯•é…ç½®åŠ è½½
  - [ ] æµ‹è¯•æ¨¡å‹åŠ è½½
  - [ ] æµ‹è¯• API ç«¯ç‚¹

### è°ƒè¯•æŠ€å·§

**1. å¿«é€Ÿå®šä½å¯¼å…¥é”™è¯¯ï¼š**
```python
# test_imports.py
import sys

print("Testing imports...")
print("=" * 60)

try:
    from config import IMAGE_SIZE, BASE_SIZE, TOKENIZER
    print("âœ… config.py: OK")
    print(f"   IMAGE_SIZE = {IMAGE_SIZE}")
    print(f"   TOKENIZER type = {type(TOKENIZER)}")
except Exception as e:
    print(f"âŒ config.py: {e}")

try:
    from deepseek_ocr import DeepseekOCRForCausalLM
    print("âœ… deepseek_ocr.py: OK")
except Exception as e:
    print(f"âŒ deepseek_ocr.py: {e}")

try:
    from process.image_process import DeepseekOCRProcessor
    print("âœ… process/image_process.py: OK")
except Exception as e:
    print(f"âŒ process/image_process.py: {e}")

print("=" * 60)
print("Done.")
```

**2. æ£€æŸ¥ GPU çŠ¶æ€ï¼š**
```bash
# å®æ—¶ç›‘æ§ GPU
watch -n 1 nvidia-smi

# æŸ¥æ‰¾å ç”¨ GPU çš„è¿›ç¨‹
fuser -v /dev/nvidia*
```

**3. æ¸…ç†åƒµå°¸è¿›ç¨‹ï¼š**
```bash
# æŸ¥æ‰¾ Python è¿›ç¨‹
ps aux | grep python | grep -v grep

# ç»ˆæ­¢æŒ‡å®šè¿›ç¨‹
kill <PID>

# å¦‚æœæ— æ³•ç»ˆæ­¢ï¼Œå¼ºåˆ¶æ€æ­»
kill -9 <PID>
```

### æ–‡æ¡£è®°å½•

**è¿ç§»è¿‡ç¨‹ä¸­åº”è¯¥è®°å½•ï¼š**
1. åŸå§‹é¡¹ç›®è·¯å¾„å’Œç‰ˆæœ¬
2. è¿ç§»çš„ç›®çš„å’ŒèŒƒå›´
3. ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨
4. é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
5. ç¯å¢ƒé…ç½®ä¿¡æ¯
6. å¯åŠ¨å’ŒéªŒè¯æ­¥éª¤

**æœ¬æ–‡æ¡£æœ¬èº«å°±æ˜¯è¿™ç§è®°å½•çš„ä¸€éƒ¨åˆ†ï¼Œæ–¹ä¾¿æœªæ¥å‚è€ƒã€‚**

---

## æ€»ç»“

æœ¬æ¬¡è¿ç§»é—®é¢˜çš„æ ¸å¿ƒæ˜¯**é—æ¼äº†å…³é”®çš„æ¨¡å‹é…ç½®æ–‡ä»¶**ï¼Œå¯¼è‡´äº†ä¸€è¿ä¸²çš„å¯åŠ¨å¤±è´¥ã€‚é€šè¿‡é€æ­¥è°ƒè¯•å’Œå¯¹æ¯”åŸå§‹é¡¹ç›®ï¼Œæœ€ç»ˆæ‰¾åˆ°äº†é—®é¢˜æ ¹æºå¹¶æˆåŠŸè§£å†³ã€‚

**å…³é”®è¦ç‚¹ï¼š**
1. ğŸ” è¿ç§»æ—¶è¦å…¨é¢æ£€æŸ¥ä¾èµ–å…³ç³»
2. ğŸ“ åŒåæ–‡ä»¶è¦ç‰¹åˆ«æ³¨æ„å…¶å†…å®¹å’Œç”¨é€”
3. âœ… åˆ†æ­¥éªŒè¯æ¯”ä¸€æ¬¡æ€§å¯åŠ¨æ›´å¯é 
4. ğŸ“š è¯¦ç»†è®°å½•é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆæœ‰åŠ©äºæœªæ¥å‚è€ƒ

---

## é™„å½•

### ç›¸å…³æ–‡æ¡£

- [README.md](./README.md) - é¡¹ç›®è¯´æ˜æ–‡æ¡£
- [docs/DEPLOYMENT.md](./docs/DEPLOYMENT.md) - éƒ¨ç½²æŒ‡å—
- [docs/architecture.md](./docs/architecture.md) - æ¶æ„æ–‡æ¡£

### æœ‰ç”¨çš„å‘½ä»¤

```bash
# æ£€æŸ¥å¯¼å…¥ä¾èµ–
grep -r "from config import" --include="*.py" -n

# æ£€æŸ¥æ–‡ä»¶å·®å¼‚
diff original_file.py new_file.py

# ç›‘æ§ GPU ä½¿ç”¨
watch -n 1 nvidia-smi

# æµ‹è¯•ç¯å¢ƒé…ç½®
python -c "import sys; print(sys.path)"

# æŸ¥æ‰¾è¿›ç¨‹
ps aux | grep python

# ç«¯å£æ£€æŸ¥
netstat -tunlp | grep 8080
```

---

**æ–‡æ¡£ç‰ˆæœ¬:** 1.0
**æœ€åæ›´æ–°:** 2025-12-29
**ä½œè€…:** Claude Code & sixiaomin
